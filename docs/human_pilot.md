# Human Pilot Study: Perceived Social Intelligence of MToM Agents

## 1. Purpose and Scope

This document describes a human-in-the-loop pilot evaluation conducted to assess whether agents equipped with a Machine Theory of Mind (MToM) are perceived by humans as more socially intelligent than baseline agents.

The study evaluates perceptual outcomes—warmth, competence, and trust—and is intended as a proof-of-concept validation of the proposed framework. It does not aim to establish clinical, diagnostic, or deployment-level claims.

## 2. Study Design

### 2.1 Design Overview

The study followed a within-subjects comparative design, where participants evaluated short interaction transcripts generated by two agent types:

- **Baseline agent** (task-reward–only optimization)
- **MToM agent** (belief-based social reasoning)

Each participant viewed multiple dialogues from both agent types, presented in randomized order to mitigate ordering effects.

### 2.2 Stimuli

- **Stimulus format:** Short negotiation dialogues (text-based)
- **Number of dialogues:** 12 total
  - 6 generated by the MToM agent
  - 6 generated by the baseline agent
- **Dialogue source:** Pre-generated interaction logs from the controlled negotiation environment
- **Length:** Each dialogue consisted of 2–4 turns

All dialogues were matched for task structure and length to isolate perceived social behavior rather than task difficulty.

## 3. Participants

- **Sample size:** N = 25
- **Recruitment platform:** Online recruitment (e.g., Prolific or equivalent)
- **Inclusion criteria:**
  - Age ≥ 18 years
  - Fluent in English
- **Exclusion criteria:** None beyond consent refusal

No demographic variables (e.g., age, gender, nationality) were collected, in order to:

- minimize participant burden,
- preserve anonymity,
- and reduce unnecessary personal data collection.

## 4. Procedure

1. Participants accessed the study via a web-based interface.
2. An informed consent statement was displayed; participation proceeded only after explicit consent.
3. Participants viewed the 12 dialogues in randomized order.
4. After each dialogue, participants rated the agent on three dimensions:
   - Warmth
   - Competence
   - Trust
5. Upon completion, participants received a generated completion code for verification.

**Total study duration:** approximately 5–8 minutes.

## 5. Measures

All ratings used **7-point Likert scales:**

- **Warmth:**
  - 1 = Cold / Unfriendly
  - 7 = Warm / Trustworthy

- **Competence:**
  - 1 = Inept / Ineffective
  - 7 = Highly Capable

- **Trust:**
  - 1 = Cannot Be Trusted
  - 7 = Fully Trustworthy

These dimensions are well-established in the social cognition literature and align with the latent variables modeled by the MToM framework.

## 6. Data Collection and Storage

**Collected data fields:**

- Dialogue identifier
- Agent type (baseline or MToM)
- Warmth rating
- Competence rating
- Trust rating
- Timestamp
- Completion code

**Data format:** CSV

**Storage:** Local secure storage within the repository (`data/human_pilot/`)

**Privacy:**

- No personally identifiable information (PII) collected
- No free-text responses collected
- Only aggregated and anonymized results are reported in the paper.

## 7. Statistical Analysis

- **Primary comparisons:** MToM vs baseline
- **Statistical test:** Welch's two-sample t-test (unequal variances)
- **Significance level:** α = 0.05 (two-tailed)
- **Effect size:** Cohen's d
- **Confidence intervals:** 95%

Analyses were conducted on aggregated dialogue-level ratings per participant to avoid inflating sample size.

## 8. Results Summary

Across all three dimensions—warmth, competence, and trust—the MToM agent was rated significantly higher than the baseline agent.

Effect sizes were large, indicating substantial perceptual differences despite the modest sample size.

These findings are consistent with simulation-based improvements in social alignment and Theory-of-Mind accuracy captured by the SIQ metric.

## 9. Ethical Considerations

- Participation was voluntary and based on explicit informed consent.
- No deception was used.
- No sensitive, personal, or clinical information was collected.
- The study posed minimal risk to participants.
- The evaluation concerns perceived social behavior of artificial agents, not mental health or diagnosis.

As such, the study falls within the scope of minimal-risk, non-clinical human-subjects research.

## 10. Limitations

- Small sample size (pilot study)
- Short, text-based interactions
- Simulated negotiation context
- Cultural background of participants not recorded

These limitations are consistent with the proof-of-concept nature of the evaluation and motivate future, larger-scale studies.

## 11. Relation to the Main Paper

This human pilot complements simulation-based results by demonstrating that:

- explicit belief modeling improves human-perceived social intelligence,
- improvements in SIQ correspond to perceptual judgments,
- and MToM reasoning is not merely an internal optimization artifact.

Formal results and statistical tables are reported in the main paper (Section 7).

---

## Summary

This human-in-the-loop pilot provides preliminary empirical evidence that Machine Theory of Mind agents are perceived as warmer, more competent, and more trustworthy than task-optimized baselines, supporting the central claims of the framework while remaining within ethical and methodological bounds appropriate for early-stage research.
